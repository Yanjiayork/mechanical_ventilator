{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals  \n",
    "\n",
    "import numpy as np\n",
    "import IPython\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import influence.experiments as experiments\n",
    "from influence.all_CNN_1d import All_CNN_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import influence.dataset as dataset\n",
    "from influence.dataset import DataSet\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### creating the dataset which is consistent with the dataset modul \n",
    "\n",
    "\n",
    "train_set=pd.read_csv('data_vent/train_set.csv')\n",
    "val_set=pd.read_csv('data_vent/val_set.csv')\n",
    "test_set=pd.read_csv('data_vent/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy=pd.read_csv('data_vent/trainy.csv')\n",
    "valy=pd.read_csv('data_vent/valy.csv')\n",
    "testy=pd.read_csv('data_vent/testy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_vent/orginal_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the range between 0 and 1\n",
    "column = list(train_set.columns.values)\n",
    "for col in column:\n",
    "    minimum = df[col].min()\n",
    "    maximum = df[col].max()\n",
    "    train_set[col] = (train_set[col] - minimum)/(maximum-minimum)\n",
    "    val_set[col] = (val_set[col] - minimum)/(maximum-minimum)\n",
    "    test_set[col] = (test_set[col] - minimum)/(maximum-minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.iloc[104:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy = trainy.iloc[104:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175872, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admittype</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Admission Weight (Kg)</th>\n",
       "      <th>Heart Rate</th>\n",
       "      <th>Respiratory Rate</th>\n",
       "      <th>O2 saturation pulseoxymetry</th>\n",
       "      <th>Inspired O2 Fraction</th>\n",
       "      <th>PEEP set</th>\n",
       "      <th>...</th>\n",
       "      <th>Peak Insp. Pressure</th>\n",
       "      <th>O2 Flow</th>\n",
       "      <th>Plateau Pressure</th>\n",
       "      <th>Arterial O2 pressure</th>\n",
       "      <th>Arterial CO2 Pressure</th>\n",
       "      <th>Arterial Blood Pressure systolic</th>\n",
       "      <th>Arterial Blood Pressure diastolic</th>\n",
       "      <th>Arterial Blood Pressure mean</th>\n",
       "      <th>SBT_value</th>\n",
       "      <th>ventilator_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165179</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.378505</td>\n",
       "      <td>0.258721</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165179</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.378505</td>\n",
       "      <td>0.258721</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165179</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.251572</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.378505</td>\n",
       "      <td>0.258721</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165179</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.378505</td>\n",
       "      <td>0.258721</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165179</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.270440</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.378505</td>\n",
       "      <td>0.258721</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Admittype  Ethnicity  Gender       Age  Admission Weight (Kg)  \\\n",
       "104        1.0        0.0     0.0  0.165179               0.567901   \n",
       "105        1.0        0.0     0.0  0.165179               0.567901   \n",
       "106        1.0        0.0     0.0  0.165179               0.567901   \n",
       "107        1.0        0.0     0.0  0.165179               0.567901   \n",
       "108        1.0        0.0     0.0  0.165179               0.567901   \n",
       "\n",
       "     Heart Rate  Respiratory Rate  O2 saturation pulseoxymetry  \\\n",
       "104    0.333333          0.142857                         0.96   \n",
       "105    0.264151          0.214286                         0.98   \n",
       "106    0.251572          0.171429                         0.96   \n",
       "107    0.283019          0.178571                         0.96   \n",
       "108    0.270440          0.221429                         0.96   \n",
       "\n",
       "     Inspired O2 Fraction  PEEP set  ...  Peak Insp. Pressure  O2 Flow  \\\n",
       "104                  0.35  0.333333  ...             0.322581     0.48   \n",
       "105                  0.35  0.333333  ...             0.322581     0.48   \n",
       "106                  0.36  0.333333  ...             0.322581     0.48   \n",
       "107                  0.36  0.333333  ...             0.322581     0.48   \n",
       "108                  0.36  0.333333  ...             0.322581     0.48   \n",
       "\n",
       "     Plateau Pressure  Arterial O2 pressure  Arterial CO2 Pressure  \\\n",
       "104             0.375              0.178218               0.895522   \n",
       "105             0.375              0.178218               0.895522   \n",
       "106             0.375              0.178218               0.895522   \n",
       "107             0.375              0.178218               0.895522   \n",
       "108             0.375              0.178218               0.895522   \n",
       "\n",
       "     Arterial Blood Pressure systolic  Arterial Blood Pressure diastolic  \\\n",
       "104                          0.382353                           0.378505   \n",
       "105                          0.382353                           0.378505   \n",
       "106                          0.382353                           0.378505   \n",
       "107                          0.382353                           0.378505   \n",
       "108                          0.382353                           0.378505   \n",
       "\n",
       "     Arterial Blood Pressure mean  SBT_value  ventilator_category  \n",
       "104                      0.258721        0.5             0.272727  \n",
       "105                      0.258721        0.5             0.272727  \n",
       "106                      0.258721        0.5             0.272727  \n",
       "107                      0.258721        0.5             0.272727  \n",
       "108                      0.258721        0.5             0.272727  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.values\n",
    "val_set = val_set.values\n",
    "test_set = test_set.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy = trainy.values\n",
    "valy = valy.values\n",
    "testy = testy.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175872, 25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy = np.reshape(trainy, (trainy.shape[0],))\n",
    "valy = np.reshape(valy, (valy.shape[0],))\n",
    "testy = np.reshape(testy, (testy.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((175872,), (24531,), (19584,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy.shape, valy.shape, testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220091, 31)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataSet(train_set, trainy)\n",
    "validation = DataSet(val_set, valy)\n",
    "test = DataSet(test_set, testy)\n",
    "data_sets = base.Datasets(train=train, validation=validation, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## start to train model#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for one epoch = 175872/128 = 1374\n",
    "# how many epoch = num_steps:100000/1374 = 72.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "input_side = 25\n",
    "input_channels = 1\n",
    "input_dim = input_side * input_channels \n",
    "#weight_decay = 0.0005\n",
    "batch_size = 128\n",
    "\n",
    "initial_learning_rate = 0.00001 \n",
    "decay_epochs = [40, 50000]\n",
    "hidden1_units = 64\n",
    "hidden2_units = 128\n",
    "hidden3_units = 256\n",
    "conv_patch_size = 1\n",
    "num_steps = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yanjia/Documents/jupyter_notebook_code/influence-release-master/influence/genericNeuralNet.py:83: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/yanjia/Documents/jupyter_notebook_code/influence-release-master/influence/genericNeuralNet.py:107: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/yanjia/Documents/jupyter_notebook_code/influence-release-master/influence/genericNeuralNet.py:108: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/yanjia/Documents/jupyter_notebook_code/influence-release-master/influence/all_CNN_1d.py:87: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/yanjia/Documents/jupyter_notebook_code/influence-release-master/influence/all_CNN_1d.py:103: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/yanjia/Documents/jupyter_notebook_code/influence-release-master/influence/genericNeuralNet.py:58: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/yanjia/Documents/jupyter_notebook_code/influence-release-master/influence/genericNeuralNet.py:402: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/yanjia/Documents/jupyter_notebook_code/influence-release-master/influence/genericNeuralNet.py:411: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/yanjia/Documents/jupyter_notebook_code/influence-release-master/influence/genericNeuralNet.py:140: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Total number of parameters: 926850\n",
      "WARNING:tensorflow:From /Users/yanjia/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = All_CNN_1d(\n",
    "    input_side=input_side, \n",
    "    input_channels=input_channels,\n",
    "    conv_patch_size=conv_patch_size,\n",
    "    hidden1_units=hidden1_units, \n",
    "    hidden2_units=hidden2_units,\n",
    "    hidden3_units=hidden3_units,\n",
    "\n",
    "    num_classes=num_classes, \n",
    "    batch_size=batch_size,\n",
    "    data_sets=data_sets,\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    damping=1e-2,\n",
    "    decay_epochs=decay_epochs,\n",
    "    mini_batch=True,\n",
    "    train_dir='output', \n",
    "    log_dir='log',\n",
    "    model_name='ventilator_all_cnn_1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100000 steps\n",
      "Step 0: loss = 3.26805592 (0.219 sec)\n",
      "Step 1000: loss = 2.45721483 (0.030 sec)\n",
      "Step 2000: loss = 2.32443023 (0.038 sec)\n",
      "Step 3000: loss = 2.04763603 (0.037 sec)\n",
      "Step 4000: loss = 1.65839386 (0.039 sec)\n",
      "Step 5000: loss = 1.35447466 (0.039 sec)\n",
      "Step 6000: loss = 1.09986842 (0.034 sec)\n",
      "Step 7000: loss = 1.06704843 (0.026 sec)\n",
      "Step 8000: loss = 0.94598138 (0.049 sec)\n",
      "Step 9000: loss = 0.92270029 (0.043 sec)\n",
      "Step 10000: loss = 0.76730639 (0.040 sec)\n",
      "Step 11000: loss = 0.82836008 (0.043 sec)\n",
      "Step 12000: loss = 0.72611588 (0.052 sec)\n",
      "Step 13000: loss = 0.71686316 (0.040 sec)\n",
      "Step 14000: loss = 0.64804137 (0.053 sec)\n",
      "Step 15000: loss = 0.63991535 (0.040 sec)\n",
      "Step 16000: loss = 0.61866343 (0.048 sec)\n",
      "Step 17000: loss = 0.52598321 (0.035 sec)\n",
      "Step 18000: loss = 0.48369598 (0.034 sec)\n",
      "Step 19000: loss = 0.47198778 (0.034 sec)\n",
      "Step 20000: loss = 0.50892937 (0.036 sec)\n",
      "Step 21000: loss = 0.50612533 (0.052 sec)\n",
      "Step 22000: loss = 0.50967830 (0.034 sec)\n",
      "Step 23000: loss = 0.49580723 (0.041 sec)\n",
      "Step 24000: loss = 0.49585027 (0.036 sec)\n",
      "Step 25000: loss = 0.50534725 (0.040 sec)\n",
      "Step 26000: loss = 0.46317160 (0.047 sec)\n",
      "Step 27000: loss = 0.37739205 (0.041 sec)\n",
      "Step 28000: loss = 0.47397631 (0.028 sec)\n",
      "Step 29000: loss = 0.40271965 (0.034 sec)\n",
      "Step 30000: loss = 0.48754567 (0.051 sec)\n",
      "Step 31000: loss = 0.42892027 (0.041 sec)\n",
      "Step 32000: loss = 0.44931608 (0.041 sec)\n",
      "Step 33000: loss = 0.40615749 (0.043 sec)\n",
      "Step 34000: loss = 0.34063941 (0.023 sec)\n",
      "Step 35000: loss = 0.33439291 (0.047 sec)\n",
      "Step 36000: loss = 0.44278669 (0.039 sec)\n",
      "Step 37000: loss = 0.48429495 (0.044 sec)\n",
      "Step 38000: loss = 0.33517087 (0.044 sec)\n",
      "Step 39000: loss = 0.41195557 (0.051 sec)\n",
      "Step 40000: loss = 0.37294900 (0.061 sec)\n",
      "Step 41000: loss = 0.40488154 (0.048 sec)\n",
      "Step 42000: loss = 0.43267485 (0.052 sec)\n",
      "Step 43000: loss = 0.29119730 (0.047 sec)\n",
      "Step 44000: loss = 0.28963721 (0.041 sec)\n",
      "Step 45000: loss = 0.37016118 (0.043 sec)\n",
      "Step 46000: loss = 0.33542147 (0.049 sec)\n",
      "Step 47000: loss = 0.26986244 (0.061 sec)\n",
      "Step 48000: loss = 0.39087844 (0.037 sec)\n",
      "Step 49000: loss = 0.44949767 (0.052 sec)\n",
      "Step 50000: loss = 0.31030548 (0.038 sec)\n",
      "Step 51000: loss = 0.36078465 (0.034 sec)\n",
      "Step 52000: loss = 0.47819370 (0.043 sec)\n",
      "Step 53000: loss = 0.38397285 (0.053 sec)\n",
      "Step 54000: loss = 0.30945441 (0.049 sec)\n",
      "Step 55000: loss = 0.31668425 (0.059 sec)\n",
      "Step 56000: loss = 0.41095892 (0.049 sec)\n",
      "Step 57000: loss = 0.43540788 (0.048 sec)\n",
      "Step 58000: loss = 0.32684159 (0.051 sec)\n",
      "Step 59000: loss = 0.30922395 (0.049 sec)\n",
      "Step 60000: loss = 0.39534217 (0.045 sec)\n",
      "Step 61000: loss = 0.35627922 (0.071 sec)\n",
      "Step 62000: loss = 0.40003687 (0.044 sec)\n",
      "Step 63000: loss = 0.33075702 (0.038 sec)\n",
      "Step 64000: loss = 0.35759982 (0.049 sec)\n",
      "Step 65000: loss = 0.31795454 (0.034 sec)\n",
      "Step 66000: loss = 0.38681078 (0.055 sec)\n",
      "Step 67000: loss = 0.28903806 (0.063 sec)\n",
      "Step 68000: loss = 0.34198570 (0.064 sec)\n",
      "Step 69000: loss = 0.32220834 (0.073 sec)\n",
      "Step 70000: loss = 0.36814609 (0.062 sec)\n",
      "Step 71000: loss = 0.32450312 (0.052 sec)\n",
      "Step 72000: loss = 0.33350748 (0.048 sec)\n",
      "Step 73000: loss = 0.34181702 (0.055 sec)\n",
      "Step 74000: loss = 0.44209814 (0.048 sec)\n",
      "Step 75000: loss = 0.33989683 (0.043 sec)\n",
      "Step 76000: loss = 0.30948126 (0.035 sec)\n",
      "Step 77000: loss = 0.34370473 (0.048 sec)\n",
      "Step 78000: loss = 0.31647834 (0.046 sec)\n",
      "Step 79000: loss = 0.24351925 (0.047 sec)\n",
      "Step 80000: loss = 0.40801382 (0.070 sec)\n",
      "Step 81000: loss = 0.37464911 (0.036 sec)\n",
      "Step 82000: loss = 0.26730436 (0.056 sec)\n",
      "Step 83000: loss = 0.25921038 (0.051 sec)\n",
      "Step 84000: loss = 0.28134921 (0.059 sec)\n",
      "Step 85000: loss = 0.32829389 (0.051 sec)\n",
      "Step 86000: loss = 0.31514868 (0.041 sec)\n",
      "Step 87000: loss = 0.33493134 (0.051 sec)\n",
      "Step 88000: loss = 0.25146046 (0.053 sec)\n",
      "Step 89000: loss = 0.30738220 (0.055 sec)\n",
      "Step 90000: loss = 0.27723378 (0.051 sec)\n",
      "Step 91000: loss = 0.36512941 (0.049 sec)\n",
      "Step 92000: loss = 0.36648780 (0.048 sec)\n",
      "Step 93000: loss = 0.34062973 (0.062 sec)\n",
      "Step 94000: loss = 0.36063451 (0.046 sec)\n",
      "Step 95000: loss = 0.29255983 (0.038 sec)\n",
      "Step 96000: loss = 0.31538886 (0.044 sec)\n",
      "Step 97000: loss = 0.29323864 (0.065 sec)\n",
      "Step 98000: loss = 0.31843632 (0.036 sec)\n",
      "Step 99000: loss = 0.34537023 (0.060 sec)\n",
      "Train loss (w reg) on all data: [0.34095057]\n",
      "Train loss (w/o reg) on all data: [0.27689267]\n",
      "Test loss (w/o reg) on all data: [0.29910378]\n",
      "Train acc on all data:  [0.88866335]\n",
      "Test acc on all data:   [0.87300858]\n",
      "Norm of the mean of gradients: 0.13669598\n",
      "Norm of the params: 11.485291\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    num_steps=num_steps, \n",
    "    iter_to_switch_to_batch=10000000,\n",
    "    iter_to_switch_to_sgd=10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### add extubation failure patients back to the training dataset #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exfailure = pd.read_csv('data_withextubation_failure/exfailure_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78611, 31)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exfailure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exfailure = df_exfailure.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78592, 31)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exfailure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "corhort_exfailure = df_exfailure['hadm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corhort_exfailure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corhort_exfailure_train = corhort_exfailure[:200]\n",
    "corhort_exfailure_test = corhort_exfailure[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 49)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corhort_exfailure_train), len(corhort_exfailure_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exfailure = pd.DataFrame()\n",
    "train_exfailure= df_exfailure.loc[df_exfailure['hadm'].isin(corhort_exfailure_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exfailure = pd.DataFrame()\n",
    "test_exfailure= df_exfailure.loc[df_exfailure['hadm'].isin(corhort_exfailure_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62412, 31)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_exfailure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exfailure = train_exfailure[:62336]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62336, 31)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_exfailure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exfailure = train_exfailure.drop(['timestamp', 'hadm', 'Admdays', 'Ventilator Mode', 'Vented'], axis=1)\n",
    "test_exfailure = test_exfailure.drop(['timestamp', 'hadm', 'Admdays', 'Ventilator Mode', 'Vented'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy_exfailure = train_exfailure['Vented_1']\n",
    "testy_exfailure = test_exfailure['Vented_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exfailure = train_exfailure.drop(['Vented_1'], axis=1)\n",
    "test_exfailure = test_exfailure.drop(['Vented_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62336, 25)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_exfailure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the range of features between 0 and 1\n",
    "column = list(train_exfailure.columns.values)\n",
    "for col in column:\n",
    "    minimum = df[col].min()\n",
    "    maximum = df[col].max()\n",
    "    train_exfailure[col] = (train_exfailure[col] - minimum)/(maximum-minimum)\n",
    "    test_exfailure[col] = (test_exfailure[col] - minimum)/(maximum-minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exfailure = train_exfailure.values\n",
    "test_exfailure = test_exfailure.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175872, 25)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_train = np.concatenate((train_set,train_exfailure),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238208, 25)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy_exfailure= trainy_exfailure.values\n",
    "testy_exfailure = testy_exfailure.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175872,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_trainy = np.concatenate((trainy,trainy_exfailure),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238208,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_trainy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modified = DataSet(modified_train, modified_trainy)\n",
    "validation = DataSet(val_set, valy)\n",
    "test = DataSet(test_set, testy)\n",
    "modified_data_sets = base.Datasets(train=train_modified, validation=validation, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 926850\n"
     ]
    }
   ],
   "source": [
    "# Train a model on the modified training set\n",
    "tf.reset_default_graph()\n",
    "\n",
    "modified_model = All_CNN_1d(\n",
    "    input_side=input_side, \n",
    "    input_channels=input_channels,\n",
    "    conv_patch_size=conv_patch_size,\n",
    "    hidden1_units=hidden1_units, \n",
    "    hidden2_units=hidden2_units,\n",
    "    hidden3_units=hidden3_units,\n",
    "\n",
    "    num_classes=num_classes, \n",
    "    batch_size=batch_size,\n",
    "    data_sets=modified_data_sets,\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "\n",
    "    decay_epochs=decay_epochs,\n",
    "    mini_batch=True,\n",
    "    train_dir='output', \n",
    "    log_dir='log',\n",
    "    model_name='ventilator_all_cnn_1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100000 steps\n",
      "Step 0: loss = 3.26805592 (0.301 sec)\n",
      "Step 1000: loss = 2.45721483 (0.038 sec)\n",
      "Step 2000: loss = 2.30711627 (0.052 sec)\n",
      "Step 3000: loss = 1.96709383 (0.042 sec)\n",
      "Step 4000: loss = 1.59284222 (0.073 sec)\n",
      "Step 5000: loss = 1.32766831 (0.042 sec)\n",
      "Step 6000: loss = 1.18162727 (0.045 sec)\n",
      "Step 7000: loss = 1.09312868 (0.057 sec)\n",
      "Step 8000: loss = 0.97583747 (0.049 sec)\n",
      "Step 9000: loss = 0.90702355 (0.049 sec)\n",
      "Step 10000: loss = 0.92665422 (0.050 sec)\n",
      "Step 11000: loss = 0.77505219 (0.040 sec)\n",
      "Step 12000: loss = 0.73768038 (0.048 sec)\n",
      "Step 13000: loss = 0.66516864 (0.056 sec)\n",
      "Step 14000: loss = 0.67886358 (0.031 sec)\n",
      "Step 15000: loss = 0.64984441 (0.040 sec)\n",
      "Step 16000: loss = 0.61172152 (0.035 sec)\n",
      "Step 17000: loss = 0.48834181 (0.037 sec)\n",
      "Step 18000: loss = 0.54849076 (0.050 sec)\n",
      "Step 19000: loss = 0.65715349 (0.037 sec)\n",
      "Step 20000: loss = 0.58777529 (0.036 sec)\n",
      "Step 21000: loss = 0.43904394 (0.052 sec)\n",
      "Step 22000: loss = 0.50492597 (0.069 sec)\n",
      "Step 23000: loss = 0.45651335 (0.041 sec)\n",
      "Step 24000: loss = 0.49449947 (0.059 sec)\n",
      "Step 25000: loss = 0.52097893 (0.048 sec)\n",
      "Step 26000: loss = 0.52110887 (0.041 sec)\n",
      "Step 27000: loss = 0.49234775 (0.061 sec)\n",
      "Step 28000: loss = 0.38919732 (0.032 sec)\n",
      "Step 29000: loss = 0.40286213 (0.054 sec)\n",
      "Step 30000: loss = 0.41793457 (0.037 sec)\n",
      "Step 31000: loss = 0.39036220 (0.049 sec)\n",
      "Step 32000: loss = 0.44867340 (0.053 sec)\n",
      "Step 33000: loss = 0.48633689 (0.033 sec)\n",
      "Step 34000: loss = 0.36671853 (0.043 sec)\n",
      "Step 35000: loss = 0.41333786 (0.044 sec)\n",
      "Step 36000: loss = 0.43648103 (0.044 sec)\n",
      "Step 37000: loss = 0.43140459 (0.047 sec)\n",
      "Step 38000: loss = 0.32158643 (0.042 sec)\n",
      "Step 39000: loss = 0.42398971 (0.035 sec)\n",
      "Step 40000: loss = 0.38728499 (0.048 sec)\n",
      "Step 41000: loss = 0.31847385 (0.062 sec)\n",
      "Step 42000: loss = 0.38165319 (0.047 sec)\n",
      "Step 43000: loss = 0.39875001 (0.048 sec)\n",
      "Step 44000: loss = 0.41266349 (0.044 sec)\n",
      "Step 45000: loss = 0.37201139 (0.056 sec)\n",
      "Step 46000: loss = 0.39880317 (0.050 sec)\n",
      "Step 47000: loss = 0.24308091 (0.053 sec)\n",
      "Step 48000: loss = 0.27494606 (0.051 sec)\n",
      "Step 49000: loss = 0.31209069 (0.053 sec)\n",
      "Step 50000: loss = 0.32726347 (0.041 sec)\n",
      "Step 51000: loss = 0.30335259 (0.038 sec)\n",
      "Step 52000: loss = 0.40035537 (0.051 sec)\n",
      "Step 53000: loss = 0.41767758 (0.055 sec)\n",
      "Step 54000: loss = 0.32368445 (0.035 sec)\n",
      "Step 55000: loss = 0.38181069 (0.049 sec)\n",
      "Step 56000: loss = 0.36733544 (0.049 sec)\n",
      "Step 57000: loss = 0.33322585 (0.047 sec)\n",
      "Step 58000: loss = 0.36084354 (0.045 sec)\n",
      "Step 59000: loss = 0.25890672 (0.061 sec)\n",
      "Step 60000: loss = 0.35126615 (0.054 sec)\n",
      "Step 61000: loss = 0.33990934 (0.053 sec)\n",
      "Step 62000: loss = 0.39007536 (0.057 sec)\n",
      "Step 63000: loss = 0.42831746 (0.041 sec)\n",
      "Step 64000: loss = 0.33303592 (0.047 sec)\n",
      "Step 65000: loss = 0.31170017 (0.032 sec)\n",
      "Step 66000: loss = 0.37020728 (0.050 sec)\n",
      "Step 67000: loss = 0.36869177 (0.041 sec)\n",
      "Step 68000: loss = 0.34081781 (0.028 sec)\n",
      "Step 69000: loss = 0.33758366 (0.060 sec)\n",
      "Step 70000: loss = 0.29179859 (0.057 sec)\n",
      "Step 71000: loss = 0.30723545 (0.066 sec)\n",
      "Step 72000: loss = 0.30424374 (0.052 sec)\n",
      "Step 73000: loss = 0.35889691 (0.055 sec)\n",
      "Step 74000: loss = 0.31109133 (0.057 sec)\n",
      "Step 75000: loss = 0.23910716 (0.049 sec)\n",
      "Step 76000: loss = 0.33446172 (0.048 sec)\n",
      "Step 77000: loss = 0.31941086 (0.047 sec)\n",
      "Step 78000: loss = 0.31538615 (0.040 sec)\n",
      "Step 79000: loss = 0.41113991 (0.055 sec)\n",
      "Step 80000: loss = 0.34043989 (0.055 sec)\n",
      "Step 81000: loss = 0.33014816 (0.053 sec)\n",
      "Step 82000: loss = 0.29852796 (0.044 sec)\n",
      "Step 83000: loss = 0.31975594 (0.051 sec)\n",
      "Step 84000: loss = 0.37558690 (0.035 sec)\n",
      "Step 85000: loss = 0.34646735 (0.056 sec)\n",
      "Step 86000: loss = 0.30813986 (0.039 sec)\n",
      "Step 87000: loss = 0.34221080 (0.050 sec)\n",
      "Step 88000: loss = 0.38101691 (0.046 sec)\n",
      "Step 89000: loss = 0.34097204 (0.035 sec)\n",
      "Step 90000: loss = 0.31339365 (0.058 sec)\n",
      "Step 91000: loss = 0.27002889 (0.044 sec)\n",
      "Step 92000: loss = 0.36264008 (0.048 sec)\n",
      "Step 93000: loss = 0.38040394 (0.035 sec)\n",
      "Step 94000: loss = 0.37814218 (0.057 sec)\n",
      "Step 95000: loss = 0.30768985 (0.043 sec)\n",
      "Step 96000: loss = 0.28119728 (0.049 sec)\n",
      "Step 97000: loss = 0.33597553 (0.048 sec)\n",
      "Step 98000: loss = 0.30272985 (0.036 sec)\n",
      "Step 99000: loss = 0.24959178 (0.047 sec)\n",
      "Train loss (w reg) on all data: [0.31831806]\n",
      "Train loss (w/o reg) on all data: [0.26824498]\n",
      "Test loss (w/o reg) on all data: [0.29302768]\n",
      "Train acc on all data:  [0.89075514]\n",
      "Test acc on all data:   [0.8724469]\n",
      "Norm of the mean of gradients: 0.22229727\n",
      "Norm of the params: 10.229744\n"
     ]
    }
   ],
   "source": [
    "modified_model.train(\n",
    "    num_steps=100000, \n",
    "    iter_to_switch_to_batch=10000000,\n",
    "    iter_to_switch_to_sgd=10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_test = modified_model.sess.run(\n",
    "    modified_model.preds,\n",
    "    feed_dict=modified_model.all_test_feed_dict)\n",
    "\n",
    "target_names = ['class 0', 'class 1']\n",
    "y_pred_test = np.argmax(y_pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.84      0.63      0.72      5051\n",
      "     class 1       0.88      0.96      0.92     14533\n",
      "\n",
      "    accuracy                           0.87     19584\n",
      "   macro avg       0.86      0.79      0.82     19584\n",
      "weighted avg       0.87      0.87      0.87     19584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testy, y_pred_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_test = model.sess.run(\n",
    "    model.preds,\n",
    "    feed_dict=model.all_test_feed_dict)\n",
    "\n",
    "target_names = ['class 0', 'class 1']\n",
    "y_pred_test = np.argmax(y_pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.81      0.67      0.73      5051\n",
      "     class 1       0.89      0.94      0.92     14533\n",
      "\n",
      "    accuracy                           0.87     19584\n",
      "   macro avg       0.85      0.81      0.82     19584\n",
      "weighted avg       0.87      0.87      0.87     19584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testy, y_pred_test, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_model_preds = model.sess.run(\n",
    "    model.preds,\n",
    "    feed_dict=model.all_test_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19584, 2)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_model_preds = np.argmax(orig_model_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_model_preds = modified_model.sess.run(\n",
    "    modified_model.preds,\n",
    "    feed_dict=modified_model.all_test_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19584, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_model_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_model_preds = np.argmax(modified_model_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_modified = []\n",
    "for i in range(len(testy)):\n",
    "    if modified_model_preds[i] != orig_model_preds[i]:\n",
    "        different_modified.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_orig = orig_model_preds[different_modified]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = testy[different_modified]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtest_id = []\n",
    "for i in range(len(true_label)):\n",
    "    if predic_orig[i] == true_label[i]:\n",
    "        mtest_id.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = true_label[mtest_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "different_modified[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of test gradient: 20.094368\n",
      "Function value: -95.76898956298828\n",
      "Split function value: 27.644641876220703, -123.4381\n",
      "Predicted loss diff on train_idx 5: -1.97940507542376e-05\n",
      "Function value: -12951.529296875\n",
      "Split function value: 9028.6220703125, -24021.26\n",
      "Predicted loss diff on train_idx 5: 0.0007471361831591246\n",
      "Function value: -129755.263671875\n",
      "Split function value: -121568.5625, -24017.256\n",
      "Predicted loss diff on train_idx 5: 0.002094636355466192\n",
      "Function value: -410037.37890625\n",
      "Split function value: -368938.28125, -23919.535\n",
      "Predicted loss diff on train_idx 5: 0.001610588988970839\n",
      "Function value: -859708.61328125\n",
      "Split function value: -839598.8125, -24925.113\n",
      "Predicted loss diff on train_idx 5: 0.007671149170315438\n",
      "Function value: -1584763.396484375\n",
      "Split function value: -1476788.875, -23644.521\n",
      "Predicted loss diff on train_idx 5: 0.002619830464112509\n",
      "Function value: -2947536.501953125\n",
      "Split function value: -2846555.25, -26928.002\n",
      "Predicted loss diff on train_idx 5: 0.014281293898740806\n",
      "Function value: -5253632.71875\n",
      "Split function value: -5414870.0, -24818.719\n",
      "Predicted loss diff on train_idx 5: 0.006618745220661932\n",
      "Function value: -8954225.837890625\n",
      "Split function value: -9022656.0, -27527.838\n",
      "Predicted loss diff on train_idx 5: 0.044162793290160283\n",
      "Function value: -9800609.41015625\n",
      "Split function value: -9528837.0, -29971.41\n",
      "Predicted loss diff on train_idx 5: 0.022026260843333346\n",
      "Function value: -13128994.453125\n",
      "Split function value: -13579251.0, -27234.453\n",
      "Predicted loss diff on train_idx 5: 0.02881885100154067\n",
      "Function value: -20083166.1875\n",
      "Split function value: -19630136.0, -32892.188\n",
      "Predicted loss diff on train_idx 5: 0.002287353769801497\n",
      "Function value: -21782188.865234375\n",
      "Split function value: -20361964.0, -30924.865\n",
      "Predicted loss diff on train_idx 5: 0.030026279554003225\n",
      "Function value: -22410350.072265625\n",
      "Split function value: -23240760.0, -30422.072\n",
      "Predicted loss diff on train_idx 5: 0.034239201696888856\n",
      "Function value: -23462535.818359375\n",
      "Split function value: -24177804.0, -30941.818\n",
      "Predicted loss diff on train_idx 5: 0.017054195496294205\n",
      "Function value: -24808889.177734375\n",
      "Split function value: -25884066.0, -30545.178\n",
      "Predicted loss diff on train_idx 5: 0.029824608951919122\n",
      "Function value: -24743366.33203125\n",
      "Split function value: -24958908.0, -30612.332\n",
      "Predicted loss diff on train_idx 5: 0.030439029388181757\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -25720782.332031\n",
      "         Iterations: 17\n",
      "         Function evaluations: 45\n",
      "         Gradient evaluations: 51\n",
      "         Hessian evaluations: 97\n",
      "Saved inverse HVP to output/ventilator_all_cnn_1d-cg-normal_loss-test-[114].npz\n",
      "Inverse HVP took 22195.90037202835 sec\n",
      "Multiplying by 238208 train examples took 3202.766848087311 sec\n"
     ]
    }
   ],
   "source": [
    "test_idx = 114\n",
    "influences_modified = modified_model.get_influence_on_test_loss(\n",
    "    test_indices=[test_idx], \n",
    "    train_idx=np.arange(len(modified_model.data_sets.train.labels)),\n",
    "    force_refresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7fcf9823b590>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k =15\n",
    "helpful_points = np.argsort(influences_modified)[-top_k:][::-1]\n",
    "unhelpful_points = np.argsort(influences_modified)[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 training points making the loss on the test point worse:\n",
      "#77475, class=1.0, predicted_loss_diff=-0.16406575\n",
      "#53233, class=1.0, predicted_loss_diff=-0.15410436\n",
      "#53231, class=1.0, predicted_loss_diff=-0.15023694\n",
      "#186003, class=0.0, predicted_loss_diff=-0.14771105\n",
      "#15304, class=0.0, predicted_loss_diff=-0.14306511\n",
      "#26556, class=0.0, predicted_loss_diff=-0.13984615\n",
      "#15307, class=0.0, predicted_loss_diff=-0.13969990\n",
      "#53229, class=1.0, predicted_loss_diff=-0.13683761\n",
      "#60841, class=1.0, predicted_loss_diff=-0.13551770\n",
      "#15301, class=0.0, predicted_loss_diff=-0.13382185\n",
      "#15320, class=0.0, predicted_loss_diff=-0.13143367\n",
      "#186004, class=0.0, predicted_loss_diff=-0.12964110\n",
      "#53235, class=1.0, predicted_loss_diff=-0.12931203\n",
      "#15306, class=0.0, predicted_loss_diff=-0.12724073\n",
      "#185745, class=1.0, predicted_loss_diff=-0.12654783\n",
      "Top 15 training points making the loss on the test point better:\n",
      "#13744, class=0.0, predicted_loss_diff=0.14803877\n",
      "#13742, class=0.0, predicted_loss_diff=0.14535237\n",
      "#13743, class=0.0, predicted_loss_diff=0.14197979\n",
      "#13798, class=0.0, predicted_loss_diff=0.13659121\n",
      "#132699, class=0.0, predicted_loss_diff=0.13090531\n",
      "#13741, class=0.0, predicted_loss_diff=0.12834721\n",
      "#13745, class=0.0, predicted_loss_diff=0.12776733\n",
      "#47996, class=0.0, predicted_loss_diff=0.12709729\n",
      "# 8490, class=0.0, predicted_loss_diff=0.12509444\n",
      "#102658, class=0.0, predicted_loss_diff=0.12316813\n",
      "#132704, class=0.0, predicted_loss_diff=0.12224987\n",
      "#155511, class=0.0, predicted_loss_diff=0.12124215\n",
      "#102659, class=0.0, predicted_loss_diff=0.12065087\n",
      "#132703, class=0.0, predicted_loss_diff=0.12010375\n",
      "#152351, class=0.0, predicted_loss_diff=0.11944133\n"
     ]
    }
   ],
   "source": [
    "influences_to_plot = []\n",
    "points_to_plot = []\n",
    "\n",
    "for points, message in [\n",
    "    (unhelpful_points, 'worse'), (helpful_points, 'better')]:\n",
    "    print(\"Top %s training points making the loss on the test point %s:\" % (top_k, message))\n",
    "    for counter, idx in enumerate(points):\n",
    "        print(\"#%5d, class=%s, predicted_loss_diff=%.8f\" % (\n",
    "            idx,                 \n",
    "            modified_trainy[idx], \n",
    "            influences_modified[idx]))\n",
    "        \n",
    "        points_to_plot.append(idx)\n",
    "        influences_to_plot.append(influences_modified[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = []\n",
    "for i in range(len(points_to_plot)):\n",
    "    if points_to_plot[i] >= 175872:\n",
    "        patient.append('extubation failiure patient')\n",
    "    else:\n",
    "        patient.append('normal patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "indication = []\n",
    "for i in range(len(points_to_plot)):\n",
    "    val = i +1 \n",
    "    indication.append(str(val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {'object': indication,'Type': patient, 'Value': influences_to_plot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {'normal patient':'C0', 'extubation failiure patient':'red'}  \n",
    "c = data_df['Type'].apply(lambda x:colors[x])\n",
    "plt.figure(figsize=(22,6))\n",
    "ax = plt.gca() \n",
    "bars= ax.bar(data_df['object'], data_df['Value'], color=c)\n",
    "plt.xlim(-0.5, len(points_to_plot)-0.5)\n",
    "plt.ylim(-0.2, 0.2)\n",
    "for i, j in colors.items(): #Loop over color dictionary\n",
    "    ax.bar(data_df['object'], data_df['Value'],width=0,color=j,label=i) #Plot invisible bar graph but have the legends specified\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238208,)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influences_modified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = influences_modified[175872:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "abovezero = []\n",
    "for i in range(len(new_points)):\n",
    "    if abs(new_points[i]) > 0.05:\n",
    "        abovezero.append(new_points[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abovezero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_order = np.argsort(abovezero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "abovezero_ordered=[]\n",
    "for i in sort_order:\n",
    "    abovezero_ordered.append(abovezero[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(22,6))\n",
    "plt.ylim(-0.15, 0.15)\n",
    "plt.xlim(0, len(abovezero)+1)\n",
    "ax = plt.gca() \n",
    "ind = np.array(np.arange(len(abovezero_ordered)))\n",
    "ax.bar(ind+1, abovezero_ordered)\n",
    "\n",
    "plt.xticks([1,50,100,150,200,250,300,350,400,414], visible=True, rotation=\"horizontal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model_preds[114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy[114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_model_preds[114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
