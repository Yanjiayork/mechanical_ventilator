{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn import preprocessing, neighbors,svm\n",
    "#from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn. ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=read_csv('data/train_set.csv')\n",
    "val_set=read_csv('data/val_set.csv')\n",
    "test_set=read_csv('data/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy=read_csv('data/trainy.csv')\n",
    "valy=read_csv('data/valy.csv')\n",
    "testy=read_csv('data/testy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv('data/orginal_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the range between 0 and 1\n",
    "column = list(train_set.columns.values)\n",
    "for col in column:\n",
    "    minimum = df[col].min()\n",
    "    maximum = df[col].max()\n",
    "    train_set[col] = (train_set[col] - minimum)/(maximum-minimum)\n",
    "    val_set[col] = (val_set[col] - minimum)/(maximum-minimum)\n",
    "    test_set[col] = (test_set[col] - minimum)/(maximum-minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.array(train_set)\n",
    "trainy= np.array(trainy).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################training decision tree#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   25.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                              class_weight={0: 3.0, 1: 1.0},\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'max_depth': [2, 5, 10, 15, 20, 25]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# defining parameter range\n",
    "param_grid_dt = {'max_depth': [2, 5, 10, 15, 20, 25]}\n",
    " \n",
    "grid = GridSearchCV(DecisionTreeClassifier(class_weight={0: 3., 1: 1.}), param_grid_dt, refit=True, verbose=1)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(train_set, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC = DecisionTreeClassifier(max_depth = 10, class_weight={0: 3., 1: 1.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC DT(AUC = 0.808 $\\pm$ 0.004)\n"
     ]
    }
   ],
   "source": [
    "aucs_dtc = []\n",
    "for i in range(20):\n",
    "    DTC.fit(train_set, trainy)\n",
    "    roc_auc_dtc = roc_auc_score(testy, DTC.predict(test_set))  \n",
    "    aucs_dtc.append(roc_auc_dtc)\n",
    "mean_auc_dtc = np.mean(aucs_dtc)\n",
    "std_auc_dtc = np.std(aucs_dtc)\n",
    "print('Mean ROC DT(AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc_dtc, std_auc_dtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################training Random FT #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(class_weight ={0: 3., 1: 1.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC RF(AUC = 0.748 $\\pm$ 0.020)\n"
     ]
    }
   ],
   "source": [
    "aucs_rf = []\n",
    "for i in range(20):\n",
    "    RF.fit(train_set, trainy)\n",
    "    roc_auc_rf = roc_auc_score(testy, RF.predict(test_set))\n",
    "    aucs_rf.append(roc_auc_rf)  \n",
    "mean_auc_rf = np.mean(aucs_rf)\n",
    "std_auc_rf = np.std(aucs_rf)\n",
    "print('Mean ROC RF(AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc_rf, std_auc_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################training Logistic regression #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(class_weight ={0: 3., 1: 1.}, solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC LR(AUC = 0.827 $\\pm$ 0.000)\n"
     ]
    }
   ],
   "source": [
    "aucs_lr = []\n",
    "for i in range(20):\n",
    "    LR.fit(train_set, trainy)\n",
    "    roc_auc_lr = roc_auc_score(testy, LR.predict(test_set))\n",
    "    aucs_lr.append(roc_auc_lr)  \n",
    "mean_auc_lr = np.mean(aucs_lr)\n",
    "std_auc_lr = np.std(aucs_lr)\n",
    "print('Mean ROC LR(AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc_lr, std_auc_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################training SVM  #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/Users/yanjia/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 75.5min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 147.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight={0: 3.0, 1: 1.0}, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [1, 10], 'gamma': ('scale', 'auto'),\n",
       "                         'kernel': ('linear', 'rbf', 'sigmoid')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# defining parameter range\n",
    "param_grid_svm = {'kernel':('linear', 'rbf', 'sigmoid'), 'C':[1, 10], 'gamma':('scale', 'auto')}\n",
    " \n",
    "grid = GridSearchCV(svm.SVC(class_weight={0: 3., 1: 1.}), param_grid_svm, refit=True, n_jobs=-1, verbose=1)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(train_set, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV = svm.SVC(kernel='rbf', C=10, gamma = 'auto', class_weight={0: 3., 1: 1.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC SVM(AUC = 0.826 $\\pm$ 0.000)\n"
     ]
    }
   ],
   "source": [
    "aucs_sv = []\n",
    "for i in range(20):\n",
    "    SV.fit(train_set, trainy)\n",
    "    roc_auc_sv = roc_auc_score(testy, SV.predict(test_set))\n",
    "    aucs_sv.append(roc_auc_sv)  \n",
    "mean_auc_sv = np.mean(aucs_sv)\n",
    "std_auc_sv = np.std(aucs_sv)\n",
    "print('Mean ROC SVM(AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc_sv, std_auc_sv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################training Neural Network #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = MLPClassifier(hidden_layer_sizes=(512,),activation='relu',solver='adam',max_iter=500, n_iter_no_change=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC NN(AUC = 0.784 $\\pm$ 0.015)\n"
     ]
    }
   ],
   "source": [
    "aucs_nn = []\n",
    "for i in range(20):\n",
    "    NN.fit(train_set, trainy)\n",
    "    roc_auc_nn = roc_auc_score(testy, NN.predict(test_set))\n",
    "    aucs_nn.append(roc_auc_nn)  \n",
    "mean_auc_nn = np.mean(aucs_nn)\n",
    "std_auc_nn = np.std(aucs_nn)\n",
    "print('Mean ROC NN(AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc_nn, std_auc_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030753575530154696"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_auc_nn *2, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
